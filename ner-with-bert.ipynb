{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":31089,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Steps \n### 1. process the wnut dataset \n### 2.make dataloader\n### 3.train and evaluate","metadata":{}},{"cell_type":"code","source":"from datasets import load_dataset\nwnut = load_dataset(\"wnut_17\")\nwnut","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-08-27T06:14:10.315548Z","iopub.execute_input":"2025-08-27T06:14:10.315842Z","iopub.status.idle":"2025-08-27T06:14:10.829384Z","shell.execute_reply.started":"2025-08-27T06:14:10.315811Z","shell.execute_reply":"2025-08-27T06:14:10.828528Z"}},"outputs":[{"execution_count":128,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['id', 'tokens', 'ner_tags'],\n        num_rows: 3394\n    })\n    validation: Dataset({\n        features: ['id', 'tokens', 'ner_tags'],\n        num_rows: 1009\n    })\n    test: Dataset({\n        features: ['id', 'tokens', 'ner_tags'],\n        num_rows: 1287\n    })\n})"},"metadata":{}}],"execution_count":128},{"cell_type":"code","source":"#wnut['train']['ner_tags']","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-27T06:14:12.990815Z","iopub.execute_input":"2025-08-27T06:14:12.991128Z","iopub.status.idle":"2025-08-27T06:14:12.995279Z","shell.execute_reply.started":"2025-08-27T06:14:12.991105Z","shell.execute_reply":"2025-08-27T06:14:12.994105Z"}},"outputs":[],"execution_count":129},{"cell_type":"code","source":"train=wnut['train']\n#train[0]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-27T06:14:13.196250Z","iopub.execute_input":"2025-08-27T06:14:13.196891Z","iopub.status.idle":"2025-08-27T06:14:13.200512Z","shell.execute_reply.started":"2025-08-27T06:14:13.196861Z","shell.execute_reply":"2025-08-27T06:14:13.199670Z"}},"outputs":[],"execution_count":130},{"cell_type":"markdown","source":"### Step1.1: tokenise the dataset with the bert tokeniser \nwhy : bert doesnt know words it knows tokens , and our taks is named entity recognition ,the entitiew oudl be the tokens it knows not the words ,","metadata":{}},{"cell_type":"markdown","source":"### step1.2 break dataset into tokens with bert tokenizer","metadata":{}},{"cell_type":"code","source":"from transformers import AutoTokenizer\n\nmodel_checkpoint = \"distilbert-base-uncased\"\ntokenizer = AutoTokenizer.from_pretrained(model_checkpoint)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-27T06:14:13.704615Z","iopub.execute_input":"2025-08-27T06:14:13.704924Z","iopub.status.idle":"2025-08-27T06:14:13.877530Z","shell.execute_reply.started":"2025-08-27T06:14:13.704899Z","shell.execute_reply":"2025-08-27T06:14:13.876897Z"}},"outputs":[],"execution_count":131},{"cell_type":"code","source":"datatokens=tokenizer(train['tokens'], truncation=True, is_split_into_words=True)\n#datatokens","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-27T06:14:15.384778Z","iopub.execute_input":"2025-08-27T06:14:15.385770Z","iopub.status.idle":"2025-08-27T06:14:15.739670Z","shell.execute_reply.started":"2025-08-27T06:14:15.385740Z","shell.execute_reply":"2025-08-27T06:14:15.738808Z"}},"outputs":[],"execution_count":132},{"cell_type":"markdown","source":"### aligh tokens with the labels","metadata":{}},{"cell_type":"code","source":"def tokenize_and_align_labels(examples):\n    tokenized_inputs = tokenizer(\n        examples[\"tokens\"],\n        truncation=True,\n        is_split_into_words=True,\n        padding=\"max_length\", \n        max_length=128\n    )\n\n    labels = []\n    for i, label in enumerate(examples[\"ner_tags\"]):\n        word_ids = tokenized_inputs.word_ids(batch_index=i)  \n        label_ids = []\n        previous_word = None\n        for word_id in word_ids:\n            if word_id is None:\n                label_ids.append(-100)\n            elif word_id != previous_word:\n                label_ids.append(label[word_id])\n            else:\n                label_ids.append(-100)\n            previous_word = word_id\n        labels.append(label_ids)\n\n    tokenized_inputs[\"labels\"] = labels\n    return tokenized_inputs\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-27T06:14:15.786527Z","iopub.execute_input":"2025-08-27T06:14:15.787119Z","iopub.status.idle":"2025-08-27T06:14:15.792954Z","shell.execute_reply.started":"2025-08-27T06:14:15.787091Z","shell.execute_reply":"2025-08-27T06:14:15.792005Z"}},"outputs":[],"execution_count":133},{"cell_type":"code","source":"tokenized_inputs=tokenize_and_align_labels(train)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-27T06:14:17.727998Z","iopub.execute_input":"2025-08-27T06:14:17.728882Z","iopub.status.idle":"2025-08-27T06:14:18.734644Z","shell.execute_reply.started":"2025-08-27T06:14:17.728855Z","shell.execute_reply":"2025-08-27T06:14:18.733676Z"}},"outputs":[],"execution_count":134},{"cell_type":"code","source":"tokenized_wnut = wnut.map( tokenize_and_align_labels, batched = True)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-27T06:14:18.736017Z","iopub.execute_input":"2025-08-27T06:14:18.736339Z","iopub.status.idle":"2025-08-27T06:14:18.770474Z","shell.execute_reply.started":"2025-08-27T06:14:18.736310Z","shell.execute_reply":"2025-08-27T06:14:18.769859Z"}},"outputs":[],"execution_count":135},{"cell_type":"markdown","source":"## step 2 we fix the padding \n:Pad dynamically at batch time\nwe will be adding padding to sequences of tokens to ensre all sequences in the batch has the same length","metadata":{}},{"cell_type":"code","source":"from transformers import DataCollatorForTokenClassification\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-27T06:14:20.558726Z","iopub.execute_input":"2025-08-27T06:14:20.559486Z","iopub.status.idle":"2025-08-27T06:14:20.563339Z","shell.execute_reply.started":"2025-08-27T06:14:20.559456Z","shell.execute_reply":"2025-08-27T06:14:20.562343Z"}},"outputs":[],"execution_count":136},{"cell_type":"code","source":"data_collator = DataCollatorForTokenClassification(tokenizer = tokenizer) #for the padding thing in the training loop the padding is handled manually so this would be used for the evlaution\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-27T06:14:20.703294Z","iopub.execute_input":"2025-08-27T06:14:20.703963Z","iopub.status.idle":"2025-08-27T06:14:20.707861Z","shell.execute_reply.started":"2025-08-27T06:14:20.703937Z","shell.execute_reply":"2025-08-27T06:14:20.706847Z"}},"outputs":[],"execution_count":137},{"cell_type":"code","source":"#!pip install -q evaluate seqeval\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-27T06:14:26.997218Z","iopub.execute_input":"2025-08-27T06:14:26.997522Z","iopub.status.idle":"2025-08-27T06:14:27.001418Z","shell.execute_reply.started":"2025-08-27T06:14:26.997497Z","shell.execute_reply":"2025-08-27T06:14:27.000506Z"}},"outputs":[],"execution_count":138},{"cell_type":"code","source":"import evaluate\nseqeval = evaluate.load(\"seqeval\") #loads the SeqEval metric, which is a standard evaluation metric for sequence labeling task here is the NER","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-27T06:14:27.213014Z","iopub.execute_input":"2025-08-27T06:14:27.213708Z","iopub.status.idle":"2025-08-27T06:14:27.496391Z","shell.execute_reply.started":"2025-08-27T06:14:27.213682Z","shell.execute_reply":"2025-08-27T06:14:27.495554Z"}},"outputs":[],"execution_count":139},{"cell_type":"markdown","source":"why we need to use this for evalaution metric?\nthe seqeval is the standard evlautation metric for sequence lableing tasks a7ki m3ehom\nthe seqeval compsed of your typical evlaution metriccs such as \nprecision -recall-f1score-accurancy but the evalaution is donde at entity level , not tokenbytoken \nwhat does that mean?\nsince what we are doing is not prediction the label fro the token we created (since we tokenised the entire dataset) we want to predict for the entire entitiy (before tokenisation)\nso the seqeval do entire entity level evalutation and \nsince the process was taking on the first part of the word when we tokenised and the second part was represented by the -100 after we do our labeling (the -100 stay -100 dont get a label) then we reconstract the original world level prediction\n ","metadata":{}},{"cell_type":"code","source":"import numpy as np\n\n\nlabel_list = wnut[\"train\"].features[f\"ner_tags\"].feature.names\n\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-27T06:14:28.861455Z","iopub.execute_input":"2025-08-27T06:14:28.861763Z","iopub.status.idle":"2025-08-27T06:14:28.866212Z","shell.execute_reply.started":"2025-08-27T06:14:28.861739Z","shell.execute_reply":"2025-08-27T06:14:28.865484Z"}},"outputs":[],"execution_count":140},{"cell_type":"code","source":"example = wnut[\"train\"][0]\nlabels = [label_list[i] for i in example[f\"ner_tags\"]]\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-27T06:14:29.028492Z","iopub.execute_input":"2025-08-27T06:14:29.029084Z","iopub.status.idle":"2025-08-27T06:14:29.033585Z","shell.execute_reply.started":"2025-08-27T06:14:29.029058Z","shell.execute_reply":"2025-08-27T06:14:29.032734Z"}},"outputs":[],"execution_count":141},{"cell_type":"code","source":"def compute_metrics(p):\n    predictions, labels = p\n    predictions = np.argmax(predictions, axis=2)\n\n    true_predictions = [\n        [label_list[p] for (p, l) in zip(prediction, label) if l != -100]\n        for prediction, label in zip(predictions, labels)\n    ]\n    true_labels = [\n        [label_list[l] for (p, l) in zip(prediction, label) if l != -100]\n        for prediction, label in zip(predictions, labels)\n    ]\n\n    results = seqeval.compute(predictions=true_predictions, references=true_labels)\n    return {\n        \"precision\": results[\"overall_precision\"],\n        \"recall\": results[\"overall_recall\"],\n        \"f1\": results[\"overall_f1\"],\n        \"accuracy\": results[\"overall_accuracy\"],\n}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-27T06:14:29.200633Z","iopub.execute_input":"2025-08-27T06:14:29.201384Z","iopub.status.idle":"2025-08-27T06:14:29.207219Z","shell.execute_reply.started":"2025-08-27T06:14:29.201356Z","shell.execute_reply":"2025-08-27T06:14:29.206322Z"}},"outputs":[],"execution_count":142},{"cell_type":"markdown","source":"## Training process","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nfrom torch.utils.data import Dataset, DataLoader\nfrom torch.optim import Adam","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-27T06:14:31.158263Z","iopub.execute_input":"2025-08-27T06:14:31.158569Z","iopub.status.idle":"2025-08-27T06:14:31.162932Z","shell.execute_reply.started":"2025-08-27T06:14:31.158546Z","shell.execute_reply":"2025-08-27T06:14:31.162011Z"}},"outputs":[],"execution_count":143},{"cell_type":"markdown","source":" the mapping of the ids of lables","metadata":{}},{"cell_type":"code","source":"id2label = {\n    0: \"O\",\n    1: \"B-corporation\",\n    2: \"I-corporation\",\n    3: \"B-creative-work\",\n    4: \"I-creative-work\",\n    5: \"B-group\",\n    6: \"I-group\",\n    7: \"B-location\",\n    8: \"I-location\",\n    9: \"B-person\",\n    10: \"I-person\",\n    11: \"B-product\",\n    12: \"I-product\",\n    }\nlabel2id = {\n    \"O\": 0,\n    \"B-corporation\": 1,\n    \"I-corporation\": 2,\n    \"B-creative-work\": 3,\n    \"I-creative-work\": 4,\n    \"B-group\": 5,\n    \"I-group\": 6,\n    \"B-location\": 7,\n    \"I-location\": 8,\n    \"B-person\": 9,\n    \"I-person\": 10,\n    \"B-product\": 11,\n    \"I-product\": 12,\n}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-27T06:14:33.334483Z","iopub.execute_input":"2025-08-27T06:14:33.335326Z","iopub.status.idle":"2025-08-27T06:14:33.340237Z","shell.execute_reply.started":"2025-08-27T06:14:33.335299Z","shell.execute_reply":"2025-08-27T06:14:33.339336Z"}},"outputs":[],"execution_count":144},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-27T06:14:33.451084Z","iopub.execute_input":"2025-08-27T06:14:33.451351Z","iopub.status.idle":"2025-08-27T06:14:33.455275Z","shell.execute_reply.started":"2025-08-27T06:14:33.451332Z","shell.execute_reply":"2025-08-27T06:14:33.454478Z"}},"outputs":[],"execution_count":145},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\ntorch.cuda.is_available()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-27T06:14:36.442317Z","iopub.execute_input":"2025-08-27T06:14:36.442577Z","iopub.status.idle":"2025-08-27T06:14:36.448362Z","shell.execute_reply.started":"2025-08-27T06:14:36.442558Z","shell.execute_reply":"2025-08-27T06:14:36.447648Z"}},"outputs":[{"execution_count":146,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}],"execution_count":146},{"cell_type":"code","source":"#train","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-27T06:14:43.282912Z","iopub.execute_input":"2025-08-27T06:14:43.283234Z","iopub.status.idle":"2025-08-27T06:14:43.287326Z","shell.execute_reply.started":"2025-08-27T06:14:43.283213Z","shell.execute_reply":"2025-08-27T06:14:43.286356Z"}},"outputs":[],"execution_count":147},{"cell_type":"code","source":"num_labels = wnut['train'].features['ner_tags'].feature.num_classes\nnum_labels","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-27T06:14:43.452556Z","iopub.execute_input":"2025-08-27T06:14:43.452891Z","iopub.status.idle":"2025-08-27T06:14:43.458539Z","shell.execute_reply.started":"2025-08-27T06:14:43.452861Z","shell.execute_reply":"2025-08-27T06:14:43.457746Z"}},"outputs":[{"execution_count":148,"output_type":"execute_result","data":{"text/plain":"13"},"metadata":{}}],"execution_count":148},{"cell_type":"code","source":"train_dataset = tokenized_wnut[\"train\"]\nval_dataset = tokenized_wnut[\"validation\"]\ntest_dataset = tokenized_wnut[\"test\"]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-27T06:14:43.649287Z","iopub.execute_input":"2025-08-27T06:14:43.649585Z","iopub.status.idle":"2025-08-27T06:14:43.654001Z","shell.execute_reply.started":"2025-08-27T06:14:43.649564Z","shell.execute_reply":"2025-08-27T06:14:43.653212Z"}},"outputs":[],"execution_count":149},{"cell_type":"markdown","source":"now since we are working with a huggin face dataset lets make the dataloader and dataset","metadata":{}},{"cell_type":"code","source":"#make dataset\nclass NER_dataset(Dataset):\n    def __init__(self,dataset):\n        self.dataset=dataset\n    def __len__(self):\n        return len(self.dataset)\n    def __getitem__(self,idx):\n        item = self.dataset[idx]\n        return {\n            \"input_ids\": torch.tensor(item['input_ids']),\n            \"attention_mask\": torch.tensor(item['attention_mask']),\n            \"labels\": torch.tensor(item['labels'])\n        }","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-27T06:22:02.453669Z","iopub.execute_input":"2025-08-27T06:22:02.454000Z","iopub.status.idle":"2025-08-27T06:22:02.459448Z","shell.execute_reply.started":"2025-08-27T06:22:02.453970Z","shell.execute_reply":"2025-08-27T06:22:02.458587Z"}},"outputs":[],"execution_count":165},{"cell_type":"code","source":"train_dataset = NER_dataset(tokenized_wnut[\"train\"])\nval_dataset = NER_dataset(tokenized_wnut[\"validation\"])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-27T06:22:02.848174Z","iopub.execute_input":"2025-08-27T06:22:02.849124Z","iopub.status.idle":"2025-08-27T06:22:02.853058Z","shell.execute_reply.started":"2025-08-27T06:22:02.849087Z","shell.execute_reply":"2025-08-27T06:22:02.852302Z"}},"outputs":[],"execution_count":166},{"cell_type":"code","source":"train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True) #in trainng the padding is handled byt itself\ndata_collator = DataCollatorForTokenClassification(tokenizer)\n\nval_loader = DataLoader(val_dataset, batch_size=16, collate_fn=data_collator)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-27T06:22:04.777287Z","iopub.execute_input":"2025-08-27T06:22:04.777889Z","iopub.status.idle":"2025-08-27T06:22:04.782574Z","shell.execute_reply.started":"2025-08-27T06:22:04.777860Z","shell.execute_reply":"2025-08-27T06:22:04.781779Z"}},"outputs":[],"execution_count":167},{"cell_type":"markdown","source":"now get the model","metadata":{}},{"cell_type":"code","source":"#we import the model\nfrom transformers import AutoModelForTokenClassification\n\nmodel = AutoModelForTokenClassification.from_pretrained(\n    \"distilbert-base-uncased\",\n    num_labels = 13,\n    id2label = id2label,\n    label2id= label2id\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-27T06:14:46.661602Z","iopub.execute_input":"2025-08-27T06:14:46.662394Z","iopub.status.idle":"2025-08-27T06:14:46.754780Z","shell.execute_reply.started":"2025-08-27T06:14:46.662365Z","shell.execute_reply":"2025-08-27T06:14:46.753860Z"}},"outputs":[{"name":"stderr","text":"Some weights of DistilBertForTokenClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}],"execution_count":153},{"cell_type":"code","source":"import torchvision\nimport torchvision.transforms.v2 as transforms\nimport torchvision.transforms.functional as F\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-27T06:14:48.401844Z","iopub.execute_input":"2025-08-27T06:14:48.402175Z","iopub.status.idle":"2025-08-27T06:14:48.406444Z","shell.execute_reply.started":"2025-08-27T06:14:48.402154Z","shell.execute_reply":"2025-08-27T06:14:48.405581Z"}},"outputs":[],"execution_count":154},{"cell_type":"code","source":"from torch.nn import CrossEntropyLoss\nfrom torch.optim import Adam\n\nloss_function = CrossEntropyLoss(ignore_index=-100) #the left behind half wanna be token but not cool enaugh\noptimizer = Adam(model.parameters(), lr=2e-5)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-27T06:14:48.557823Z","iopub.execute_input":"2025-08-27T06:14:48.558767Z","iopub.status.idle":"2025-08-27T06:14:48.564600Z","shell.execute_reply.started":"2025-08-27T06:14:48.558731Z","shell.execute_reply":"2025-08-27T06:14:48.563986Z"}},"outputs":[],"execution_count":155},{"cell_type":"code","source":"num_epochs=5","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-27T06:14:48.724988Z","iopub.execute_input":"2025-08-27T06:14:48.725497Z","iopub.status.idle":"2025-08-27T06:14:48.729232Z","shell.execute_reply.started":"2025-08-27T06:14:48.725471Z","shell.execute_reply":"2025-08-27T06:14:48.728256Z"}},"outputs":[],"execution_count":156},{"cell_type":"code","source":"model.to(device)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-27T06:14:49.744271Z","iopub.execute_input":"2025-08-27T06:14:49.744546Z","iopub.status.idle":"2025-08-27T06:14:49.852082Z","shell.execute_reply.started":"2025-08-27T06:14:49.744527Z","shell.execute_reply":"2025-08-27T06:14:49.851268Z"}},"outputs":[{"execution_count":157,"output_type":"execute_result","data":{"text/plain":"DistilBertForTokenClassification(\n  (distilbert): DistilBertModel(\n    (embeddings): Embeddings(\n      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n      (position_embeddings): Embedding(512, 768)\n      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n    (transformer): Transformer(\n      (layer): ModuleList(\n        (0-5): 6 x TransformerBlock(\n          (attention): DistilBertSdpaAttention(\n            (dropout): Dropout(p=0.1, inplace=False)\n            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n          )\n          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n          (ffn): FFN(\n            (dropout): Dropout(p=0.1, inplace=False)\n            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n            (activation): GELUActivation()\n          )\n          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n        )\n      )\n    )\n  )\n  (dropout): Dropout(p=0.1, inplace=False)\n  (classifier): Linear(in_features=768, out_features=13, bias=True)\n)"},"metadata":{}}],"execution_count":157},{"cell_type":"code","source":"next(model.parameters()).device","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-27T06:14:51.290561Z","iopub.execute_input":"2025-08-27T06:14:51.290928Z","iopub.status.idle":"2025-08-27T06:14:51.296176Z","shell.execute_reply.started":"2025-08-27T06:14:51.290904Z","shell.execute_reply":"2025-08-27T06:14:51.295278Z"}},"outputs":[{"execution_count":158,"output_type":"execute_result","data":{"text/plain":"device(type='cuda', index=0)"},"metadata":{}}],"execution_count":158},{"cell_type":"code","source":"model.train()\nfor epoch in range(num_epochs):\n    total_loss = 0\n    for input_ids, attention_mask, labels in train_loader:\n        input_ids = input_ids.to(device)\n        attention_mask = attention_mask.to(device)\n        labels = labels.to(device)\n        \n        optimizer.zero_grad()\n        \n        outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n        loss = outputs.loss  # or use loss_function(outputs.logits.view(-1, num_labels), labels.view(-1))\n        loss.backward()\n        optimizer.step()\n        \n        total_loss += loss.item()\n    print(f\"Epoch {epoch+1}, Loss: {total_loss/len(train_loader):.4f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-27T06:17:11.999697Z","iopub.execute_input":"2025-08-27T06:17:12.000029Z","iopub.status.idle":"2025-08-27T06:19:07.006615Z","shell.execute_reply.started":"2025-08-27T06:17:12.000004Z","shell.execute_reply":"2025-08-27T06:19:07.005652Z"}},"outputs":[{"name":"stdout","text":"Epoch 1, Loss: 0.2959\nEpoch 2, Loss: 0.1298\nEpoch 3, Loss: 0.0757\nEpoch 4, Loss: 0.0465\nEpoch 5, Loss: 0.0304\n","output_type":"stream"}],"execution_count":164},{"cell_type":"code","source":"def get_batch_accuracy(preds, labels):\n    mask = labels != -100\n    correct = (preds == labels) & mask\n    return correct.sum().item() / mask.sum().item()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-27T06:22:08.169359Z","iopub.execute_input":"2025-08-27T06:22:08.169626Z","iopub.status.idle":"2025-08-27T06:22:08.174236Z","shell.execute_reply.started":"2025-08-27T06:22:08.169608Z","shell.execute_reply":"2025-08-27T06:22:08.173285Z"}},"outputs":[],"execution_count":168},{"cell_type":"code","source":"model.eval()\nval_loss = 0\nval_accuracy = 0\n\nwith torch.no_grad():\n    for batch in val_loader:\n        input_ids = batch[\"input_ids\"].to(device)\n        attention_mask = batch[\"attention_mask\"].to(device)\n        labels = batch[\"labels\"].to(device)\n\n        outputs = model(\n            input_ids=input_ids,\n            attention_mask=attention_mask,\n            labels=labels\n        )\n        val_loss += outputs.loss.item()\n        \n        preds = torch.argmax(outputs.logits, dim=-1)\n        val_accuracy += get_batch_accuracy(preds, labels)\n\nval_loss /= len(val_loader)\nval_accuracy /= len(val_loader)\nprint(f\"Valid - Loss: {val_loss:.4f} Accuracy: {val_accuracy:.4f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-27T06:22:08.516878Z","iopub.execute_input":"2025-08-27T06:22:08.517202Z","iopub.status.idle":"2025-08-27T06:22:10.787647Z","shell.execute_reply.started":"2025-08-27T06:22:08.517181Z","shell.execute_reply":"2025-08-27T06:22:10.786738Z"}},"outputs":[{"name":"stdout","text":"Valid - Loss: 0.2803 Accuracy: 0.9490\n","output_type":"stream"}],"execution_count":169},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}